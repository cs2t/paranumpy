{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hello, World', 'Hello, World']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from IPython.parallel import Client\n",
    "from ipyparallel import Client \n",
    "\n",
    "# to be run from terminal: \"  ipcluster start -n 4  --profile=mpi \"\n",
    "\n",
    "c = Client(profile='mpi')\n",
    "%pxconfig --block\n",
    "print ( c.ids ) \n",
    "\n",
    "c[:].apply_sync(lambda : \"Hello, World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 2 0\n",
      "[stdout:1] 2 1\n"
     ]
    }
   ],
   "source": [
    "%%px \n",
    "\n",
    "import sys\n",
    "sys.stdout.flush()\n",
    "\n",
    "import numpy as np\n",
    "from mpi4py import MPI\n",
    "from math   import ceil \n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "print (size, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "def scatter_int (N):\n",
    "    a0    = np.zeros(N,dtype=np.int8)\n",
    "    split = np.array_split(a0,size)\n",
    "    \n",
    "    split_sizes = []\n",
    "    for i in range(0,len(split),1):\n",
    "        split_sizes = np.append(split_sizes, len(split[i]))\n",
    "    split_sizes = np.asarray(split_sizes,dtype=np.int32) \n",
    "    N_loc = comm.scatter ( split_sizes, root = 0)\n",
    "    return N_loc\n",
    "\n",
    "# for N in [5,6,7,8,9]: \n",
    "#     N_loc = scatter_int (N)\n",
    "#     print (N_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px \n",
    "\n",
    "def gen_array (dtype = np.int32, dim = 1, N1=1, N2 = 1, N3 = 1, N4 = 1 ): \n",
    "\n",
    "    vec_global = None\n",
    "#     N1 = 5\n",
    "#     N2 = 4\n",
    "#     N3 = 3\n",
    "#     N4 = 3\n",
    "\n",
    "    if (dim == 1 and rank == 0 ):\n",
    "        vec_global = np.zeros(N1, dtype=dtype )\n",
    "        for ix in range(vec_global.shape[0]):\n",
    "            vec_global[ix]= ix\n",
    "        \n",
    "    if (dim ==2 and rank == 0 ):\n",
    "        vec_global = np.zeros((N1,N2), dtype=dtype)\n",
    "        for ix in range(vec_global.shape[0]):\n",
    "            for iy in range(vec_global.shape[1]):\n",
    "                vec_global[ix,iy]=(ix) + ( vec_global.shape[1] * iy)\n",
    "\n",
    "    if (dim == 3 and rank == 0):\n",
    "        vec_global = np.zeros((N1,N2,N3),dtype=dtype)\n",
    "        for ix in range(vec_global.shape[0]):\n",
    "            for iy in range(vec_global.shape[1]):\n",
    "                for iz in range(vec_global.shape[2]):\n",
    "                    vec_global[ix,iy,iz]=(iy) + ( vec_global.shape[1] * ix) + ( vec_global.shape[2] * iz)\n",
    "\n",
    "\n",
    "    if (dim == 4 and rank == 0 ): \n",
    "        vec_global = np.zeros((N1,N2,N3,N4),dtype=dtype)\n",
    "        for ix in range(vec_global.shape[0]):\n",
    "            for iy in range(vec_global.shape[1]):\n",
    "                for iz in range(vec_global.shape[2]):\n",
    "                    for it in range(vec_global.shape[3]):\n",
    "                        vec_global[ix,iy,iz,it]=(iy) + ( vec_global.shape[1] * ix) + ( vec_global.shape[2] * iz) + ( vec_global.shape[3] * it) \n",
    "                        \n",
    "    return vec_global \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "[[ 0  7 14 21 28 35 42]\n",
      " [ 1  8 15 22 29 36 43]\n",
      " [ 2  9 16 23 30 37 44]]\n",
      "[stdout:1] None\n"
     ]
    }
   ],
   "source": [
    "%%px \n",
    "\n",
    "v = gen_array (dim = 2, N1 = 3, N2= 7 , N3=4 , N4= 4,  dtype=np.int32 ) \n",
    "print (v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px \n",
    "\n",
    "def scatter_1D_array (vec_global,dtype = np.float64):\n",
    "    if rank == 0:\n",
    "        N1 = vec_global.shape[0]\n",
    "        split = np.array_split(vec_global,size,axis = 0) #Split input array by the number of available cores\n",
    "        split_sizes = []\n",
    "        for i in range(0,len(split),1):\n",
    "            split_sizes = np.append(split_sizes, len(split[i]))\n",
    "        split_sizes_input = split_sizes \n",
    "        displacements_input = np.insert(np.cumsum(split_sizes_input),0,0)[0:-1]\n",
    "\n",
    "    else:\n",
    "    #Create variables on other cores\n",
    "        split_sizes_input = None\n",
    "        displacements_input = None\n",
    "        split = None\n",
    "        vec_global = None\n",
    "        \n",
    "    split = comm.bcast(split, root=0) #Broadcast split array to other cores\n",
    "    vec_local = np.zeros(np.shape(split[rank]),dtype=dtype) #Create array to receive subset of data on each core, where rank specifies the core\n",
    "    if   dtype == np.float64 :\n",
    "        comm.Scatterv([vec_global,split_sizes_input, displacements_input,MPI.DOUBLE],vec_local,root=0)\n",
    "    elif dtype == np.int32 : \n",
    "        comm.Scatterv([vec_global,split_sizes_input, displacements_input,MPI.INT],vec_local,root=0)\n",
    "    return vec_local\n",
    "\n",
    "def gather_1D_array ( vec_local,dtype = np.float64 ): \n",
    "\n",
    "        N1_loc = vec_local.shape[0]\n",
    "        N1 =  comm.allreduce(N1_loc,op=MPI.SUM)   # recover full size along first dimension \n",
    "        \n",
    "        if rank == 0:\n",
    "            vec_global = np.zeros([N1],dtype=dtype)             #Create output array of same size\n",
    "        else: \n",
    "            vec_global = None \n",
    "            \n",
    "        split_size_loc = vec_local.shape[0]\n",
    "        split_size = np.asarray ( comm.gather (split_size_loc, root=0))\n",
    "        \n",
    "        if rank == 0 : \n",
    "            split_sizes_output = split_size \n",
    "            displacements_output = np.insert(np.cumsum(split_sizes_output),0,0)[0:-1]\n",
    "#             print(\"Input data split into vectors of sizes %s\" %split_sizes_output )\n",
    "#             print(\"Input data split with displacements of %s\" %displacements_output)   \n",
    "        else : \n",
    "            split_sizes_output = None \n",
    "            displacements_output = None \n",
    "            \n",
    "        split_sizes_output = comm.bcast(split_sizes_output, root = 0)\n",
    "        displacements_output = comm.bcast(displacements_output, root = 0)\n",
    "\n",
    "        comm.Barrier()\n",
    "        if   dtype == np.int32 :\n",
    "            comm.Gatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.INT], root=0) #Gather output data together\n",
    "        if   dtype == np.float64 :\n",
    "            comm.Gatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.DOUBLE], root=0) #Gather output data together\n",
    "        return vec_global\n",
    "    \n",
    "\n",
    "def allgather_1D_array ( vec_local, dtype = np.float64 ): \n",
    "\n",
    "        N1_loc = vec_local.shape[0]\n",
    "        N1 =  comm.allreduce(N1_loc,op=MPI.SUM)   # recover full size along first dimension \n",
    "        \n",
    "        vec_global = np.zeros([N1],dtype=dtype)             #Create output array of same size\n",
    "\n",
    "        split_size_loc = vec_local.shape[0]\n",
    "        split_size = np.asarray ( comm.gather (split_size_loc, root=0))\n",
    "        \n",
    "        split_sizes_output = split_size \n",
    "        displacements_output = np.insert(np.cumsum(split_sizes_output),0,0)[0:-1]\n",
    "            \n",
    "        split_sizes_output = comm.bcast(split_sizes_output, root = 0)\n",
    "        displacements_output = comm.bcast(displacements_output, root = 0)\n",
    "\n",
    "        comm.Barrier()\n",
    "        if   dtype == np.int32 :\n",
    "            comm.Allgatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.INT]) #Gather output data together\n",
    "        if   dtype == np.float64 :\n",
    "            comm.Allgatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.DOUBLE]) #Gather output data together\n",
    "        return vec_global\n",
    "    \n",
    "\n",
    "# scatters a 2D double array over all ranks \n",
    "\n",
    "def scatter_2D_array ( vec_global, dtype=np.float64 ): \n",
    "\n",
    "    if rank == 0:\n",
    "        N1 = vec_global.shape[0]\n",
    "        N2 = vec_global.shape[1]\n",
    "        \n",
    "        split = np.array_split(vec_global,size,axis = 0) #Split input array by the number of available cores\n",
    "        split_sizes = []\n",
    "        for i in range(0,len(split),1):\n",
    "            split_sizes = np.append(split_sizes, len(split[i]))\n",
    "\n",
    "        split_sizes_input = split_sizes * N2\n",
    "        displacements_input = np.insert(np.cumsum(split_sizes_input),0,0)[0:-1]\n",
    "\n",
    "    else:\n",
    "    #Create variables on other cores\n",
    "        split_sizes_input = None\n",
    "        displacements_input = None\n",
    "        split = None\n",
    "        vec_global = None\n",
    "        \n",
    "    split = comm.bcast(split, root=0) #Broadcast split array to other cores\n",
    "    vec_local = np.zeros(np.shape(split[rank]),dtype=dtype) #Create array to receive subset of data on each core, where rank specifies the core\n",
    "    if   dtype == np.float64:\n",
    "        comm.Scatterv([vec_global,split_sizes_input, displacements_input,MPI.DOUBLE],vec_local,root=0)\n",
    "    elif dtype == np.int32:\n",
    "        comm.Scatterv([vec_global,split_sizes_input, displacements_input,MPI.INT],vec_local,root=0)\n",
    "        \n",
    "    return vec_local\n",
    "\n",
    "\n",
    "\n",
    "def gather_2D_array ( vec_local , dtype=np.float64): \n",
    "\n",
    "        N1_loc = vec_local.shape[0]\n",
    "        N2     = vec_local.shape[1]\n",
    "        \n",
    "        N1 =  comm.allreduce(N1_loc,op=MPI.SUM)   # recover full size along first dimension \n",
    "        \n",
    "        if rank == 0:\n",
    "            vec_global = np.zeros([N1,N2],dtype=dtype)             #Create output array of same size\n",
    "        else: \n",
    "            vec_global = None \n",
    "            \n",
    "        split_size_loc = vec_local.shape[0]\n",
    "        split_size = np.asarray ( comm.gather (split_size_loc, root=0))\n",
    "        \n",
    "        if rank == 0 : \n",
    "            split_sizes_output = split_size * N2\n",
    "            displacements_output = np.insert(np.cumsum(split_sizes_output),0,0)[0:-1]\n",
    "        else : \n",
    "            split_sizes_output = None \n",
    "            displacements_output = None \n",
    "        split_sizes_output = comm.bcast(split_sizes_output, root = 0)\n",
    "        displacements_output = comm.bcast(displacements_output, root = 0)\n",
    "\n",
    "        comm.Barrier()\n",
    "        if   dtype == np.float64:\n",
    "            comm.Gatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.DOUBLE], root=0) #Gather output data together\n",
    "        if   dtype == np.int32:\n",
    "            comm.Gatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.INT], root=0) #Gather output data together\n",
    "        return vec_global\n",
    "\n",
    "def allgather_2D_array ( vec_local , dtype=np.float64): \n",
    "\n",
    "        N1_loc = vec_local.shape[0]\n",
    "        N2     = vec_local.shape[1]\n",
    "        \n",
    "        N1 =  comm.allreduce(N1_loc,op=MPI.SUM)   # recover full size along first dimension \n",
    "        \n",
    "        vec_global = np.zeros([N1,N2],dtype=dtype)             #Create output array of same size\n",
    "\n",
    "        split_size_loc = vec_local.shape[0]\n",
    "        split_size = np.asarray ( comm.gather (split_size_loc, root=0))\n",
    "        \n",
    "        if rank == 0 : \n",
    "            split_sizes_output = split_size * N2\n",
    "            displacements_output = np.insert(np.cumsum(split_sizes_output),0,0)[0:-1]\n",
    "        else : \n",
    "            split_sizes_output = None \n",
    "            displacements_output = None \n",
    "        split_sizes_output = comm.bcast(split_sizes_output, root = 0)\n",
    "        displacements_output = comm.bcast(displacements_output, root = 0)\n",
    "\n",
    "        comm.Barrier()\n",
    "        if   dtype == np.float64:\n",
    "            comm.Allgatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.DOUBLE]) #Gather output data together\n",
    "        if   dtype == np.int32:\n",
    "            comm.Allgatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.INT]) #Gather output data together\n",
    "        return vec_global\n",
    "\n",
    "\n",
    "def scatter_3D_array ( vec_global, dtype = np.float64 ): \n",
    "    \n",
    "    if rank == 0:\n",
    "        N1 = vec_global.shape[0]\n",
    "        N2 = vec_global.shape[1]\n",
    "        N3 = vec_global.shape[2]\n",
    "        \n",
    "        split = np.array_split(vec_global,size,axis = 0) #Split input array by the number of available cores\n",
    "        split_sizes = []\n",
    "        for i in range(0,len(split),1):\n",
    "            split_sizes = np.append(split_sizes, len(split[i]))\n",
    "            \n",
    "        split_sizes_input = split_sizes * N2 * N3 \n",
    "        displacements_input = np.insert(np.cumsum(split_sizes_input),0,0)[0:-1]\n",
    "\n",
    "    else:\n",
    "    #Create variables on other cores\n",
    "        split_sizes_input = None\n",
    "        displacements_input = None\n",
    "        split = None\n",
    "        vec_global = None\n",
    "        \n",
    "    split = comm.bcast(split, root=0) #Broadcast split array to other cores\n",
    "    vec_local = np.zeros(np.shape(split[rank]), dtype = dtype) #Create array to receive subset of data on each core, where rank specifies the core\n",
    "    if dtype == np.float64 : \n",
    "        comm.Scatterv([vec_global,split_sizes_input, displacements_input,MPI.DOUBLE],vec_local,root=0)\n",
    "    if dtype == np.int32 : \n",
    "        comm.Scatterv([vec_global,split_sizes_input, displacements_input,MPI.INT],vec_local,root=0)\n",
    "    return vec_local\n",
    "\n",
    "\n",
    "def gather_3D_array ( vec_local, dtype = np.float64  ): \n",
    "        N1_loc = vec_local.shape[0]\n",
    "        N2     = vec_local.shape[1]\n",
    "        N3     = vec_local.shape[2]\n",
    "        \n",
    "        N1 =  comm.allreduce(N1_loc,op=MPI.SUM)   # recover full size along first dimension \n",
    "        \n",
    "        if rank == 0:\n",
    "            vec_global = np.zeros([N1,N2,N3],dtype = dtype)             #Create output array of same size\n",
    "        else: \n",
    "            vec_global = None \n",
    "            \n",
    "        split_size_loc = vec_local.shape[0]\n",
    "        split_size = np.asarray ( comm.gather (split_size_loc, root=0))\n",
    "        \n",
    "        if rank == 0 : \n",
    "            split_sizes_output = split_size * N2 * N3 \n",
    "            displacements_output = np.insert(np.cumsum(split_sizes_output),0,0)[0:-1]\n",
    "        else : \n",
    "            split_sizes_output = None \n",
    "            displacements_output = None \n",
    "        split_sizes_output = comm.bcast(split_sizes_output, root = 0)\n",
    "        displacements_output = comm.bcast(displacements_output, root = 0)\n",
    "\n",
    "        comm.Barrier()\n",
    "        if dtype == np.float64 : \n",
    "            comm.Gatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.DOUBLE], root=0) #Gather output data together\n",
    "        if dtype == np.int32 : \n",
    "            comm.Gatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.INT], root=0) #Gather output data together\n",
    "\n",
    "        return vec_global\n",
    "    \n",
    "\n",
    "def allgather_3D_array ( vec_local , dtype = np.float64  ): \n",
    "\n",
    "        N1_loc = vec_local.shape[0]\n",
    "        N2     = vec_local.shape[1]\n",
    "        N3     = vec_local.shape[2]\n",
    "        \n",
    "        N1 =  comm.allreduce(N1_loc,op=MPI.SUM)   # recover full size along first dimension \n",
    "        \n",
    "        vec_global = np.zeros([N1,N2,N3],dtype=dtype)             #Create output array of same size\n",
    "\n",
    "        split_size_loc = vec_local.shape[0]\n",
    "        split_size = np.asarray ( comm.gather (split_size_loc, root=0))\n",
    "        \n",
    "        if rank == 0 : \n",
    "            split_sizes_output = split_size * N2 * N3\n",
    "            displacements_output = np.insert(np.cumsum(split_sizes_output),0,0)[0:-1]\n",
    "        else : \n",
    "            split_sizes_output = None \n",
    "            displacements_output = None \n",
    "        split_sizes_output = comm.bcast(split_sizes_output, root = 0)\n",
    "        displacements_output = comm.bcast(displacements_output, root = 0)\n",
    "\n",
    "        comm.Barrier()\n",
    "        if dtype == np.float64 : \n",
    "            comm.Allgatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.DOUBLE]) #Gather output data together\n",
    "        if dtype == np.int32 : \n",
    "            comm.Allgatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.INT]) #Gather output data together\n",
    "        return vec_global\n",
    "\n",
    "\n",
    "    \n",
    "def scatter_4D_array ( vec_global, dtype = np.float64 ): \n",
    "    \n",
    "    if rank == 0:\n",
    "        \n",
    "        N1 = vec_global.shape[0]\n",
    "        N2 = vec_global.shape[1]\n",
    "        N3 = vec_global.shape[2]\n",
    "        N4 = vec_global.shape[3]\n",
    "        \n",
    "        split = np.array_split(vec_global,size,axis = 0) #Split input array by the number of available cores\n",
    "        split_sizes = []\n",
    "        for i in range(0,len(split),1):\n",
    "            split_sizes = np.append(split_sizes, len(split[i]))\n",
    "            \n",
    "        split_sizes_input = split_sizes * N2 * N3 * N4 \n",
    "        displacements_input = np.insert(np.cumsum(split_sizes_input),0,0)[0:-1]\n",
    "\n",
    "    else:\n",
    "    #Create variables on other cores\n",
    "        split_sizes_input = None\n",
    "        displacements_input = None\n",
    "        split = None\n",
    "        vec_global = None\n",
    "        \n",
    "    split = comm.bcast(split, root=0) #Broadcast split array to other cores\n",
    "    vec_local = np.zeros(np.shape(split[rank]),dtype=dtype) #Create array to receive subset of data on each core, where rank specifies the core\n",
    "    if dtype == np.float64 : \n",
    "        comm.Scatterv([vec_global,split_sizes_input, displacements_input,MPI.DOUBLE],vec_local,root=0)\n",
    "    if dtype == np.int32 : \n",
    "        comm.Scatterv([vec_global,split_sizes_input, displacements_input,MPI.INT],vec_local,root=0)\n",
    "    return vec_local\n",
    "\n",
    "\n",
    "def gather_4D_array ( vec_local, dtype = np.float64 ): \n",
    "        N1_loc = vec_local.shape[0]\n",
    "        N2     = vec_local.shape[1]\n",
    "        N3     = vec_local.shape[2]\n",
    "        N4     = vec_local.shape[3]\n",
    "        \n",
    "        N1 =  comm.allreduce(N1_loc,op=MPI.SUM)   # recover full size along first dimension \n",
    "        \n",
    "        if rank == 0:\n",
    "            vec_global = np.zeros([N1,N2,N3,N4],dtype=dtype)             #Create output array of same size\n",
    "        else: \n",
    "            vec_global = None \n",
    "            \n",
    "        split_size_loc = vec_local.shape[0]\n",
    "        split_size = np.asarray ( comm.gather (split_size_loc, root=0))\n",
    "        \n",
    "        if rank == 0 : \n",
    "            split_sizes_output = split_size * N2 * N3 * N4 \n",
    "            displacements_output = np.insert(np.cumsum(split_sizes_output),0,0)[0:-1]\n",
    "        else : \n",
    "            split_sizes_output = None \n",
    "            displacements_output = None \n",
    "        split_sizes_output = comm.bcast(split_sizes_output, root = 0)\n",
    "        displacements_output = comm.bcast(displacements_output, root = 0)\n",
    "\n",
    "        comm.Barrier()\n",
    "        if dtype == np.float64 : \n",
    "            comm.Gatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.DOUBLE], root=0) #Gather output data together\n",
    "        if dtype == np.int32 : \n",
    "            comm.Gatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.INT], root=0) #Gather output data together\n",
    "        return vec_global\n",
    "    \n",
    "\n",
    "def allgather_4D_array ( vec_local, dtype = np.float64 ): \n",
    "\n",
    "        N1_loc = vec_local.shape[0]\n",
    "        N2     = vec_local.shape[1]\n",
    "        N3     = vec_local.shape[2]\n",
    "        N4     = vec_local.shape[3]\n",
    "        \n",
    "        N1 =  comm.allreduce(N1_loc,op=MPI.SUM)   # recover full size along first dimension \n",
    "        \n",
    "        vec_global = np.zeros([N1,N2,N3,N4], dtype=dtype)             #Create output array of same size\n",
    "\n",
    "        split_size_loc = vec_local.shape[0]\n",
    "        split_size = np.asarray ( comm.gather (split_size_loc, root=0))\n",
    "        \n",
    "        if rank == 0 : \n",
    "            split_sizes_output = split_size * N2 * N3 * N4 \n",
    "            displacements_output = np.insert(np.cumsum(split_sizes_output),0,0)[0:-1]\n",
    "        else : \n",
    "            split_sizes_output = None \n",
    "            displacements_output = None \n",
    "        split_sizes_output = comm.bcast(split_sizes_output, root = 0)\n",
    "        displacements_output = comm.bcast(displacements_output, root = 0)\n",
    "\n",
    "        comm.Barrier()\n",
    "        if dtype == np.float64 :         \n",
    "            comm.Allgatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.DOUBLE]) #Gather output data together\n",
    "        if dtype == np.int32 :         \n",
    "            comm.Allgatherv(vec_local,[vec_global,split_sizes_output,displacements_output,MPI.INT]) #Gather output data together\n",
    "        return vec_global\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "True\n",
      "True\n",
      "[stdout:1] \n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "# 1D -- Scatter, Gather, Allgather - np.int32 VERSION \n",
    "vec_in_glob      = gen_array            ( dim = 1, N1 = 7, dtype = np.int32 ) \n",
    "vec_local        = scatter_1D_array     ( vec_in_glob,     dtype = np.int32 ) \n",
    "vec_out_glob     = gather_1D_array      ( vec_local,       dtype = np.int32 ) \n",
    "vec_out_glob_all = allgather_1D_array   ( vec_local,       dtype = np.int32 ) \n",
    "# print (vec_in_glob)\n",
    "# print (vec_local)\n",
    "# print (vec_out_glob)\n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob) ) \n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob_all) ) # should be equal only on root "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "True\n",
      "True\n",
      "[stdout:1] \n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "# 1D -- Scatter, Gather, Allgather - np.float64 VERSION \n",
    "vec_in_glob      = gen_array            ( dim = 1, N1 = 7, dtype = np.float64 ) \n",
    "vec_local        = scatter_1D_array     ( vec_in_glob,     dtype = np.float64 ) \n",
    "vec_out_glob     = gather_1D_array      ( vec_local,       dtype = np.float64 ) \n",
    "vec_out_glob_all = allgather_1D_array   ( vec_local,       dtype = np.float64 ) \n",
    "# print (vec_in_glob)\n",
    "# print (vec_local)\n",
    "# print (vec_out_glob)\n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob) ) \n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob_all) ) # should be True only on root "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "True\n",
      "True\n",
      "[stdout:1] \n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "# 2D -- Scatter, Gather, Allgather - np.float64 VERSION \n",
    "vec_in_glob      = gen_array    ( dim = 2, N1 = 7, N2 = 5, dtype = np.float64 ) \n",
    "vec_local        = scatter_2D_array     ( vec_in_glob,     dtype = np.float64 ) \n",
    "vec_out_glob     = gather_2D_array      ( vec_local,       dtype = np.float64 ) \n",
    "vec_out_glob_all = allgather_2D_array   ( vec_local,       dtype = np.float64 ) \n",
    "# print (vec_in_glob)\n",
    "# print (vec_local)\n",
    "# print (vec_out_glob)\n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob) ) \n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob_all) ) # should be equal only on root \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "True\n",
      "True\n",
      "[stdout:1] \n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "# 2D -- Scatter, Gather, Allgather - np.int32 VERSION \n",
    "vec_in_glob      = gen_array    ( dim = 2, N1 = 7, N2 = 5, dtype = np.int32 ) \n",
    "vec_local        = scatter_2D_array     ( vec_in_glob,     dtype = np.int32 ) \n",
    "vec_out_glob     = gather_2D_array      ( vec_local,       dtype = np.int32 ) \n",
    "vec_out_glob_all = allgather_2D_array   ( vec_local,       dtype = np.int32 ) \n",
    "# print (vec_in_glob)\n",
    "# print (vec_local)\n",
    "# print (vec_out_glob)\n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob) ) \n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob_all) ) # should be equal only on root \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "True\n",
      "True\n",
      "[stdout:1] \n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "# 3D -- Scatter, Gather, Allgather - np.float64 VERSION \n",
    "vec_in_glob      = gen_array    ( dim = 3, N1 = 7, N2 = 5, N3 = 5, dtype = np.float64 ) \n",
    "vec_local        = scatter_3D_array             ( vec_in_glob,     dtype = np.float64 ) \n",
    "vec_out_glob     = gather_3D_array              ( vec_local,       dtype = np.float64 ) \n",
    "vec_out_glob_all = allgather_3D_array           ( vec_local,       dtype = np.float64 ) \n",
    "# print (vec_in_glob)\n",
    "# print (vec_local)\n",
    "# print (vec_out_glob)\n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob) ) \n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob_all) ) # should be equal only on root \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "True\n",
      "True\n",
      "[stdout:1] \n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "# 3D -- Scatter, Gather, Allgather - np.int32 VERSION \n",
    "vec_in_glob      = gen_array    ( dim = 3, N1 = 7, N2 = 5, N3 = 5, dtype = np.int32 ) \n",
    "vec_local        = scatter_3D_array     ( vec_in_glob,     dtype = np.int32 ) \n",
    "vec_out_glob     = gather_3D_array      ( vec_local,       dtype = np.int32 ) \n",
    "vec_out_glob_all = allgather_3D_array   ( vec_local,       dtype = np.int32 ) \n",
    "# print (vec_in_glob)\n",
    "# print (vec_local)\n",
    "# print (vec_out_glob)\n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob) ) \n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob_all) ) # should be equal only on root "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "True\n",
      "True\n",
      "[stdout:1] \n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "# 4D -- Scatter, Gather, Allgather - np.float64 VERSION \n",
    "vec_in_glob      = gen_array    ( dim = 4, N1 = 7, N2 = 5, N3 = 5, N4 = 3, dtype = np.float64 ) \n",
    "vec_local        = scatter_4D_array             ( vec_in_glob,     dtype = np.float64 ) \n",
    "vec_out_glob     = gather_4D_array              ( vec_local,       dtype = np.float64 ) \n",
    "vec_out_glob_all = allgather_4D_array           ( vec_local,       dtype = np.float64 ) \n",
    "# print (vec_in_glob)\n",
    "# print (vec_local)\n",
    "# print (vec_out_glob)\n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob) ) \n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob_all) ) # should be equal only on root \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "True\n",
      "True\n",
      "[stdout:1] \n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "# 4D -- Scatter, Gather, Allgather - np.int32 VERSION \n",
    "vec_in_glob      = gen_array    ( dim = 4, N1 = 100, N2 = 100, N3 = 50, N4 = 3, dtype = np.int32 ) \n",
    "# print (vec_in_glob)\n",
    "vec_local        = scatter_4D_array             ( vec_in_glob,     dtype = np.int32 ) \n",
    "vec_out_glob     = gather_4D_array              ( vec_local,       dtype = np.int32 ) \n",
    "vec_out_glob_all = allgather_4D_array           ( vec_local,       dtype = np.int32 ) \n",
    "# print (vec_in_glob)\n",
    "# print (vec_local)\n",
    "# print (vec_out_glob)\n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob) ) \n",
    "print ( np.array_equal (vec_in_glob, vec_out_glob_all) ) # should be equal only on root \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "(1, 2, 3, 4)\n",
      "(1, 4, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "v      = gen_array    ( dim = 4, N1 = 1, N2 =2, N3 = 3, N4 = 4, dtype = np.int32 ) \n",
    "if rank ==0 :\n",
    "    print(v.shape)\n",
    "    v1 = np.swapaxes (v,1,3)\n",
    "    print(v1.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
